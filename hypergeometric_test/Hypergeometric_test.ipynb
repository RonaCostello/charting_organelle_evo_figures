{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import pandas as pd\n",
    "import os\n",
    "import click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = ['C', 'M', 'S', 'P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C gains\n",
      "6.85562143810134e-14\n",
      "C losses\n",
      "7.508008441548733e-25\n",
      "M gains\n",
      "5.741886450965299e-29\n",
      "M losses\n",
      "8.255949762160953e-12\n",
      "S gains\n",
      "3.409124553125209e-30\n",
      "S losses\n",
      "2.2292249083350475e-28\n",
      "P gains\n",
      "0.000117203953463733\n",
      "P losses\n",
      "8.218398959819862e-05\n"
     ]
    }
   ],
   "source": [
    "directory = '/Users/rona/data/teraserve/chapter-1/IQtrees/relocalisation_duplication'\n",
    "for i, item in enumerate(locations):\n",
    "    file_1 = pd.read_csv(f\"{directory}/output_{item}_gain.csv\")\n",
    "    file_2 = pd.read_csv(f\"{directory}/output_{item}_loss.csv\")\n",
    "    \n",
    "    x_gains = file_1['reloc_following_dup'].sum()\n",
    "    M_gains = file_1['number_of_dups'].sum() + file_1['number_of_specs'].sum()\n",
    "    n_gains = file_1['reloc_following_spec'].sum() + file_1['reloc_following_dup'].sum()\n",
    "    N_gains = file_1['number_of_dups'].sum()\n",
    "    print(item + ' gains')\n",
    "    print(hypergeom.sf(x_gains-1, M_gains, n_gains, N_gains))\n",
    "    \n",
    "    x_losses = file_2['reloc_following_dup'].sum()\n",
    "    M_losses = file_2['number_of_dups'].sum() + file_2['number_of_specs'].sum()\n",
    "    n_losses = file_2['reloc_following_spec'].sum() + file_2['reloc_following_dup'].sum()\n",
    "    N_losses = file_2['number_of_dups'].sum()\n",
    "    \n",
    "    print(item + ' losses')\n",
    "    print(hypergeom.sf(x_losses-1, M_losses, n_losses, N_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:paper01_figures]",
   "language": "python",
   "name": "conda-env-paper01_figures-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
